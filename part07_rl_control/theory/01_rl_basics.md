---
layout: clean
title: 01_rl_basics
permalink: /part07_rl_control/theory/01_rl_basics.html
---

---

# ğŸ§  01. å¼·åŒ–å­¦ç¿’ã®åŸºæœ¬æ§‹é€ ï¼ˆRL Basicsï¼‰

> â„¹ï¸ æ•°å¼ãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œãªã„å ´åˆã¯ã€[GitHubç‰ˆã¯ã“ã¡ã‚‰](https://github.com/Samizo-AITL/EduController/blob/main/part07_rl_control/theory/01_rl_basics.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

æœ¬ç¯€ã§ã¯ã€**å¼·åŒ–å­¦ç¿’ï¼ˆReinforcement Learning, RLï¼‰**ã®åŸºæœ¬æ§‹é€ ã¨ä¸»è¦ãªç”¨èªãƒ»æ¦‚å¿µã‚’è§£èª¬ã—ã¾ã™ã€‚  
RLã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ**ç’°å¢ƒã¨ç›¸äº’ä½œç”¨ã—ãªãŒã‚‰æœ€é©ãªè¡Œå‹•ãƒãƒªã‚·ãƒ¼ã‚’å­¦ç¿’**ã™ã‚‹æ çµ„ã¿ã«åŸºã¥ãã¾ã™ã€‚

This section explains the **basic structure, terminology, and concepts** of Reinforcement Learning (RL).  
RL is based on the idea that an agent **learns optimal policies through interaction with the environment**.

---

## ğŸ¯ å¼·åŒ–å­¦ç¿’ã®åŸºæœ¬è¦ç´ ï¼ˆMDPï¼‰ / RL Fundamentals (MDP)

å¼·åŒ–å­¦ç¿’ã¯ã€**ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ï¼ˆMarkov Decision Process, MDPï¼‰**ã¨ã—ã¦å®šå¼åŒ–ã•ã‚Œã¾ã™ã€‚

| è¦ç´  / Element | å†…å®¹ / Description |
|------|------|
| $S$  | çŠ¶æ…‹ç©ºé–“ï¼ˆState Spaceï¼‰ |
| $A$  | è¡Œå‹•ç©ºé–“ï¼ˆAction Spaceï¼‰ |
| $R$  | å ±é…¬é–¢æ•° $r(s, a)$ |
| $P$  | é·ç§»ç¢ºç‡ $P(s'|s, a)$ |
| $\pi$ | ãƒãƒªã‚·ãƒ¼ï¼ˆæ–¹ç­–ï¼‰ï¼šçŠ¶æ…‹â†’è¡Œå‹•ã®å†™åƒ / Stateâ†’Action mapping $\pi(a|s)$ |

---

## ğŸ”„ å­¦ç¿’ã®æµã‚Œï¼ˆAgentâ€“Environment Loopï¼‰

1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçŠ¶æ…‹ $s_t$ ã‚’è¦³æ¸¬  
   Agent observes current state $s_t$
2. ãƒãƒªã‚·ãƒ¼ $\pi$ ã«åŸºã¥ãè¡Œå‹• $a_t$ ã‚’é¸æŠ  
   Agent selects action $a_t$ based on $\pi$
3. ç’°å¢ƒãŒæ–°ã—ã„çŠ¶æ…‹ $s_{t+1}$ ã¨å ±é…¬ $r_t$ ã‚’è¿”ã™  
   Environment returns new state $s_{t+1}$ and reward $r_t$
4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå ±é…¬ã«åŸºã¥ã $\pi$ ã‚’æ›´æ–°  
   Agent updates $\pi$ based on the reward
5. ä¸Šè¨˜ã‚’ç¹°ã‚Šè¿”ã—ã€ç´¯ç©å ±é…¬ã‚’æœ€å¤§åŒ–  
   Loop continues to maximize cumulative rewards

---

## ğŸ“ å ±é…¬ã¨ç›®çš„é–¢æ•° / Rewards & Objective Function

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç›®çš„ã¯ã€**ç´¯ç©å ±é…¬ï¼ˆReturnï¼‰**ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã™ã€‚

- å‰²å¼•ç´¯ç©å ±é…¬ï¼ˆDiscounted Returnï¼‰  
  $$
  G_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k}
  $$
  - $\gamma \in [0, 1)$ï¼šå‰²å¼•ç‡ / Discount factor (e.g., 0.99)

---

## ğŸ§® æ–¹ç­–ã¨ä¾¡å€¤é–¢æ•° / Policy & Value Functions

- æ–¹ç­–ï¼ˆPolicyï¼‰ï¼š$\pi(a|s)$  
  - çŠ¶æ…‹ã«å¯¾ã™ã‚‹è¡Œå‹•é¸æŠã®ç¢ºç‡åˆ†å¸ƒã¾ãŸã¯æ±ºå®šè«–çš„é–¢æ•°
- çŠ¶æ…‹ä¾¡å€¤é–¢æ•°ï¼ˆState Value Functionï¼‰ï¼š  
  $$
  V^\pi(s) = \mathbb{E}[G_t \mid s_t = s, \pi]
  $$
- è¡Œå‹•ä¾¡å€¤é–¢æ•°ï¼ˆAction Value Functionï¼‰ï¼š  
  $$
  Q^\pi(s, a) = \mathbb{E}[G_t \mid s_t = s, a_t = a, \pi]
  $$

---

## ğŸ”§ ãƒ¢ãƒ‡ãƒ«ãƒ•ãƒªãƒ¼ vs ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ / Model-Free vs Model-Based

| ç¨®é¡ / Type | ç‰¹å¾´ / Characteristics |
|--------------|------------------------|
| ãƒ¢ãƒ‡ãƒ«ãƒ•ãƒªãƒ¼ / Model-Free | ç’°å¢ƒãƒ¢ãƒ‡ãƒ«ãªã—ã€‚Qå­¦ç¿’ã€Policy Gradientãªã© |
| ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ / Model-Based | é·ç§»ãƒ¢ãƒ‡ãƒ«ã‚’æ¨å®šãƒ»åˆ©ç”¨ã€‚MPCã«è¿‘ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ |

---

## ğŸ” ä¸»ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†é¡ / Main Algorithm Categories

| ç³»çµ± / Category | ä¾‹ / Examples |
|----------------|--------------|
| å€¤ãƒ™ãƒ¼ã‚¹ / Value-Based | Q-learning, DQN |
| æ–¹ç­–ãƒ™ãƒ¼ã‚¹ / Policy-Based | Policy Gradient, REINFORCE |
| ã‚¢ã‚¯ã‚¿ãƒ¼ãƒ»ã‚¯ãƒªãƒ†ã‚£ãƒƒã‚¯ / Actor-Critic | A2C, DDPG, PPOï¼ˆé€£ç¶šåˆ¶å¾¡å‘ã‘ï¼‰ |

---

## ğŸ› ï¸ åˆ¶å¾¡å¿œç”¨ã§ã®ç‰¹å¾´ / RL in Control Applications

- **ãƒ¢ãƒ‡ãƒ«ä¸è¦**ï¼ˆModel-Freeåˆ¶å¾¡ï¼‰  
- **é©å¿œæ€§ãƒ»æŸ”è»Ÿæ€§ãŒé«˜ã„**ï¼ˆéç·šå½¢ãƒ»ãƒã‚¤ã‚ºè€æ€§ï¼‰  
- è¨“ç·´ã‚³ã‚¹ãƒˆãƒ»æ™‚é–“ãŒå¤§ãã„ã€å®‰å®šæ€§ä¿è¨¼ãŒé›£ã—ã„  
- PIDç­‰ã®å¤å…¸åˆ¶å¾¡ã¨ã®**ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­è¨ˆ**ãŒæœ‰åŠ¹

---

## ğŸ”š ã¾ã¨ã‚ / Summary

å¼·åŒ–å­¦ç¿’ã¯ã€ã€Œè©¦è¡ŒéŒ¯èª¤ï¼‹å ±é…¬ã€ã«åŸºã¥ãåˆ¶å¾¡æˆ¦ç•¥ã‚’ç²å¾—ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚  
æ¬¡ç¯€ã§ã¯ã€å€’ç«‹æŒ¯å­åˆ¶å¾¡ï¼ˆCartPoleï¼‰ã¸ã®RLé©ç”¨ä¾‹ã‚’é€šã—ã¦ã€å®Ÿè£…ã¨æŒ™å‹•ã‚’å­¦ã³ã¾ã™ã€‚

---

**â¡ï¸ [æ¬¡ç¯€ / Next: 02. å€’ç«‹æŒ¯å­ DDPGå®Ÿè£…](https://samizo-aitl.github.io/EduController/part07_rl_control/theory/02_cartpole_ddpg.html)**  
Applies RL to cartpole control using the DDPG algorithm.

**ğŸ  [Part 07 ãƒˆãƒƒãƒ— / Back to Part 07 Top](https://samizo-aitl.github.io/EduController/part07_rl_control/)**
