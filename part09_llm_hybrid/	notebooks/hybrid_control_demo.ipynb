{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Control Demo (Self-contained)\n",
    "*No external imports required. This notebook defines FSM √ó PID √ó LLM mock inline and runs the demo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inline: FSM √ó PID √ó LLM mock simulator ---\n",
    "import time, random\n",
    "\n",
    "class FSM_PID_LLM_Simulator:\n",
    "    def __init__(self):\n",
    "        self.states = ['IDLE', 'MOVE', 'AVOID', 'CHARGE']\n",
    "        self.current_state = 'IDLE'\n",
    "        self.logs = []\n",
    "\n",
    "    def pid_control(self, setpoint, measurement):\n",
    "        error = setpoint - measurement\n",
    "        return 0.5 * error  # simple P control\n",
    "\n",
    "    def llm_decision(self, state, context):\n",
    "        if \"battery low\" in context:\n",
    "            return 'CHARGE'\n",
    "        elif \"obstacle\" in context:\n",
    "            return 'AVOID'\n",
    "        elif \"task start\" in context:\n",
    "            return 'MOVE'\n",
    "        else:\n",
    "            return 'IDLE'\n",
    "\n",
    "    def step(self, t):\n",
    "        context = random.choice([\"normal\", \"battery low\", \"obstacle ahead\", \"task start\"])\n",
    "        next_state = self.llm_decision(self.current_state, context)\n",
    "        log = {\"time\": t, \"state\": self.current_state, \"context\": context, \"llm_suggest\": next_state}\n",
    "        if next_state != self.current_state:\n",
    "            log[\"transition\"] = f\"{self.current_state} ‚Üí {next_state}\"\n",
    "            self.current_state = next_state\n",
    "        if self.current_state == 'MOVE':\n",
    "            setpoint = 10.0\n",
    "            measurement = random.uniform(7.0, 12.0)\n",
    "            control = self.pid_control(setpoint, measurement)\n",
    "            log[\"pid\"] = {\"target\": setpoint, \"measured\": measurement, \"output\": control}\n",
    "        elif self.current_state == 'AVOID':\n",
    "            log[\"action\"] = \"Avoiding obstacle\"\n",
    "        elif self.current_state == 'CHARGE':\n",
    "            log[\"action\"] = \"Charging\"\n",
    "        else:\n",
    "            log[\"action\"] = \"System idle\"\n",
    "        self.logs.append(log)\n",
    "        return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inline: GoalReasoningAgent ---\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass\n",
    "class GoalReasoningAgent:\n",
    "    initial_goal: str = \"IDLE\"\n",
    "    verbose: bool = True\n",
    "    rules: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"battery low\": \"CHARGE\",\n",
    "        \"obstacle\": \"AVOID\",\n",
    "        \"destination\": \"NAVIGATE\",\n",
    "        \"task start\": \"MOVE\",\n",
    "    })\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.current_goal = self.initial_goal\n",
    "\n",
    "    def decide_next_goal(self, observation_text: str):\n",
    "        obs_lc = (observation_text or \"\").lower()\n",
    "        matched, next_goal = None, self.current_goal\n",
    "        for key, goal in self.rules.items():\n",
    "            if key in obs_lc:\n",
    "                matched, next_goal = key, goal\n",
    "                break\n",
    "        changed = (next_goal != self.current_goal)\n",
    "        if self.verbose:\n",
    "            print(f\"üß† Observation: {observation_text}\")\n",
    "            print(f\"üîé Matched rule: {matched}\" if matched else \"‚ÑπÔ∏è  No rule matched\")\n",
    "            print(f\"üéØ Goal updated: {self.current_goal} ‚Üí {next_goal}\" if changed else f\"‚úîÔ∏è Goal remains: {self.current_goal}\")\n",
    "        self.current_goal = next_goal\n",
    "        return next_goal, {\"matched_rule\": matched, \"changed\": changed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sim = FSM_PID_LLM_Simulator()\n",
    "logs = [sim.step(t) for t in range(40)]\n",
    "df = pd.json_normalize(logs).fillna('')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last rows\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state over time\n",
    "state_to_idx = {s:i for i,s in enumerate(['IDLE','MOVE','AVOID','CHARGE'])}\n",
    "y = [state_to_idx.get(s, -1) for s in df['state']]\n",
    "x = df['time']\n",
    "\n",
    "plt.figure()\n",
    "plt.step(x, y, where='post')\n",
    "plt.yticks(list(state_to_idx.values()), list(state_to_idx.keys()))\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(\"state\")\n",
    "plt.title(\"FSM State over Time (Self-contained)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoalReasoningAgent demo\n",
    "agent = GoalReasoningAgent(initial_goal=\"IDLE\", verbose=True)\n",
    "samples = [\"task start received\", \"obstacle near\", \"battery low\", \"destination ahead\"]\n",
    "for obs in samples:\n",
    "    goal, meta = agent.decide_next_goal(obs)\n",
    "    print({\"obs\": obs, \"goal\": goal, **meta})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
